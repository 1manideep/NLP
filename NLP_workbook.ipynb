{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N-gram Models (without using any libraries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Ngram:\n",
    "    def __init__(self, text, n=None):\n",
    "        self.text = text\n",
    "        self.n = n\n",
    "        self.split_text = self.process()\n",
    "\n",
    "    def process(self):\n",
    "        text = self.text.lower()\n",
    "        text = text.replace('.', ' ')\n",
    "        text = text.replace(',', ' ')\n",
    "        split_text = text.split()\n",
    "        return split_text\n",
    "\n",
    "    def ngram_context(self):\n",
    "        ngram_list, context_list = [], []\n",
    "        n = self.n\n",
    "        for i in range(0, len(self.split_text) - n + 1):\n",
    "            ngram = self.split_text[i:i + n]\n",
    "            context = self.split_text[i:i + n - 1]\n",
    "            context_list.append(context)\n",
    "            ngram_list.append(ngram)\n",
    "        return ngram_list, context_list\n",
    "\n",
    "    def counts(self, ingram):\n",
    "        ngramcount = 0\n",
    "        contextcount = 0\n",
    "        ngram_list = self.ngram_context()[0]\n",
    "        context_list = self.ngram_context()[1]\n",
    "\n",
    "        for i in ngram_list:\n",
    "            if i == ingram:\n",
    "                ngramcount += 1\n",
    "\n",
    "        for i in context_list:\n",
    "            if i == ingram[:-1]:\n",
    "                contextcount += 1\n",
    "\n",
    "        return ngramcount, contextcount\n",
    "\n",
    "    def probability(self, ingram):\n",
    "        ngram_list, context_list = self.ngram_context()\n",
    "        ncount, ccount = self.counts(ingram)\n",
    "\n",
    "        # Check for division by zero\n",
    "        if ccount == 0:\n",
    "            return 0.0\n",
    "\n",
    "        prob = ncount / ccount\n",
    "        return prob\n",
    "\n",
    "    def perplexity(self):\n",
    "        ngram_list = self.ngram_context()\n",
    "        prob = 1\n",
    "        for i in ngram_list:\n",
    "            prob_i = self.probability(i)\n",
    "\n",
    "            # Check if prob_i is 0.0, and if so, assign a small positive value (e.g., 1e-10)\n",
    "            if prob_i == 0.0:\n",
    "                prob_i = 1e-10\n",
    "\n",
    "            prob = prob * prob_i\n",
    "\n",
    "        # Check if prob is still 0.0 after the loop\n",
    "        if prob == 0.0:\n",
    "            return float('inf')  # Return infinity to indicate undefined perplexity\n",
    "        else:\n",
    "            perp = prob ** (-1 / self.n)\n",
    "            return perp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['this',\n",
       " 'is',\n",
       " 'a',\n",
       " 'test',\n",
       " 'it',\n",
       " 'has',\n",
       " 'some',\n",
       " 'punctuation',\n",
       " 'like',\n",
       " 'commas',\n",
       " 'and',\n",
       " 'periods']"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"This is a test. It has some punctuation, like commas and periods.\"\n",
    "ngram = Ngram(text)\n",
    "ngram.split_text \n",
    "#assert ngram.split_text == ['this', 'is', 'a', 'test', 'it', 'has', 'some', 'punctuation', 'like', 'commas', 'and', 'periods']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['this', 'is', 'a'], ['is', 'a', 'test'], ['a', 'test', 'it'], ['test', 'it', 'has'], ['it', 'has', 'some'], ['has', 'some', 'punctuation'], ['some', 'punctuation', 'like'], ['punctuation', 'like', 'commas'], ['like', 'commas', 'and'], ['commas', 'and', 'periods']]\n",
      "[['this', 'is'], ['is', 'a'], ['a', 'test'], ['test', 'it'], ['it', 'has'], ['has', 'some'], ['some', 'punctuation'], ['punctuation', 'like'], ['like', 'commas'], ['commas', 'and']]\n"
     ]
    }
   ],
   "source": [
    "text = \"This is a test. It has some punctuation, like commas and periods.\"\n",
    "ngram = Ngram(text, n=3)\n",
    "ngram_list, context_list = ngram.ngram_context()\n",
    "print(ngram_list)\n",
    "print(context_list)\n",
    "#assert ngram_list == [['this', 'is', 'a'], ['is', 'a', 'test'], ['a', 'test', 'it'], ['test', 'it', 'has'], ['it', 'has', 'some'], ['has', 'some', 'punctuation'], ['some', 'punctuation', 'like'], ['punctuation', 'like', 'commas'], ['like', 'commas', 'and'], ['commas', 'and', 'periods']]\n",
    "#assert context_list == [['this', 'is'], ['is', 'a'], ['a', 'test'], ['test', 'it'], ['it', 'has'], ['has', 'some'], ['some', 'punctuation'], ['punctuation', 'like'], ['like', 'commas'], ['commas', 'and']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['this', 'is'], ['is', 'a'], ['a', 'test'], ['test', 'it'], ['it', 'has'], ['has', 'some'], ['some', 'punctuation'], ['punctuation', 'this'], ['this', 'like'], ['like', 'commas'], ['commas', 'and'], ['and', 'this'], ['this', 'periods']]\n",
      "[['this'], ['is'], ['a'], ['test'], ['it'], ['has'], ['some'], ['punctuation'], ['this'], ['like'], ['commas'], ['and'], ['this']]\n",
      "1\n",
      "3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3333333333333333"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"This is a test. It has some punctuation, this like commas and  this periods.\"\n",
    "ngram = Ngram(text, n=2)\n",
    "ngram_list, context_list = ngram.ngram_context()\n",
    "print(ngram_list)\n",
    "print(context_list)\n",
    "ngramcount  = ngram.counts([ 'this', 'is'])[0]\n",
    "contextcount = ngram.counts([ 'this', 'is'])[1]\n",
    "print(ngramcount) \n",
    "print(contextcount)\n",
    "prob = ngram.probability(['this', 'is'])\n",
    "prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"This is a test. It has some punctuation, like commas and periods.\"\n",
    "ngram = Ngram(text, n=2)\n",
    "prob = ngram.probability(['this', 'is'])\n",
    "prob "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000000000.0"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"This is a test. It has some punctuation, like commas and periods.\"\n",
    "ngram = Ngram(text, n=2)\n",
    "perp = ngram.perplexity()\n",
    "perp "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"In the vast expanse of the universe, countless galaxies twinkle like distant stars, each harboring its own unique collection of celestial bodies, from massive black holes to shimmering nebulae, all governed by the laws of physics and the mysterious forces that shape the cosmos\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Ngram(text,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['in',\n",
       " 'the',\n",
       " 'vast',\n",
       " 'expanse',\n",
       " 'of',\n",
       " 'the',\n",
       " 'universe',\n",
       " 'countless',\n",
       " 'galaxies',\n",
       " 'twinkle',\n",
       " 'like',\n",
       " 'distant',\n",
       " 'stars',\n",
       " 'each',\n",
       " 'harboring',\n",
       " 'its',\n",
       " 'own',\n",
       " 'unique',\n",
       " 'collection',\n",
       " 'of',\n",
       " 'celestial',\n",
       " 'bodies',\n",
       " 'from',\n",
       " 'massive',\n",
       " 'black',\n",
       " 'holes',\n",
       " 'to',\n",
       " 'shimmering',\n",
       " 'nebulae',\n",
       " 'all',\n",
       " 'governed',\n",
       " 'by',\n",
       " 'the',\n",
       " 'laws',\n",
       " 'of',\n",
       " 'physics',\n",
       " 'and',\n",
       " 'the',\n",
       " 'mysterious',\n",
       " 'forces',\n",
       " 'that',\n",
       " 'shape',\n",
       " 'the',\n",
       " 'cosmos']"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.process()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['in', 'the', 'vast'], ['the', 'vast', 'expanse'], ['vast', 'expanse', 'of'], ['expanse', 'of', 'the'], ['of', 'the', 'universe'], ['the', 'universe', 'countless'], ['universe', 'countless', 'galaxies'], ['countless', 'galaxies', 'twinkle'], ['galaxies', 'twinkle', 'like'], ['twinkle', 'like', 'distant'], ['like', 'distant', 'stars'], ['distant', 'stars', 'each'], ['stars', 'each', 'harboring'], ['each', 'harboring', 'its'], ['harboring', 'its', 'own'], ['its', 'own', 'unique'], ['own', 'unique', 'collection'], ['unique', 'collection', 'of'], ['collection', 'of', 'celestial'], ['of', 'celestial', 'bodies'], ['celestial', 'bodies', 'from'], ['bodies', 'from', 'massive'], ['from', 'massive', 'black'], ['massive', 'black', 'holes'], ['black', 'holes', 'to'], ['holes', 'to', 'shimmering'], ['to', 'shimmering', 'nebulae'], ['shimmering', 'nebulae', 'all'], ['nebulae', 'all', 'governed'], ['all', 'governed', 'by'], ['governed', 'by', 'the'], ['by', 'the', 'laws'], ['the', 'laws', 'of'], ['laws', 'of', 'physics'], ['of', 'physics', 'and'], ['physics', 'and', 'the'], ['and', 'the', 'mysterious'], ['the', 'mysterious', 'forces'], ['mysterious', 'forces', 'that'], ['forces', 'that', 'shape'], ['that', 'shape', 'the'], ['shape', 'the', 'cosmos']]\n"
     ]
    }
   ],
   "source": [
    "ngram = model.ngram_context()[0]\n",
    "print(ngram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['in', 'the'], ['the', 'vast'], ['vast', 'expanse'], ['expanse', 'of'], ['of', 'the'], ['the', 'universe'], ['universe', 'countless'], ['countless', 'galaxies'], ['galaxies', 'twinkle'], ['twinkle', 'like'], ['like', 'distant'], ['distant', 'stars'], ['stars', 'each'], ['each', 'harboring'], ['harboring', 'its'], ['its', 'own'], ['own', 'unique'], ['unique', 'collection'], ['collection', 'of'], ['of', 'celestial'], ['celestial', 'bodies'], ['bodies', 'from'], ['from', 'massive'], ['massive', 'black'], ['black', 'holes'], ['holes', 'to'], ['to', 'shimmering'], ['shimmering', 'nebulae'], ['nebulae', 'all'], ['all', 'governed'], ['governed', 'by'], ['by', 'the'], ['the', 'laws'], ['laws', 'of'], ['of', 'physics'], ['physics', 'and'], ['and', 'the'], ['the', 'mysterious'], ['mysterious', 'forces'], ['forces', 'that'], ['that', 'shape'], ['shape', 'the']]\n"
     ]
    }
   ],
   "source": [
    "context = model.ngram_context()[1]\n",
    "print(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count of this ['in', 'the', 'vast'] is 1\n",
      "count of this ['the', 'vast', 'expanse'] is 1\n",
      "count of this ['vast', 'expanse', 'of'] is 1\n",
      "count of this ['expanse', 'of', 'the'] is 1\n",
      "count of this ['of', 'the', 'universe'] is 1\n",
      "count of this ['the', 'universe', 'countless'] is 1\n",
      "count of this ['universe', 'countless', 'galaxies'] is 1\n",
      "count of this ['countless', 'galaxies', 'twinkle'] is 1\n",
      "count of this ['galaxies', 'twinkle', 'like'] is 1\n",
      "count of this ['twinkle', 'like', 'distant'] is 1\n",
      "count of this ['like', 'distant', 'stars'] is 1\n",
      "count of this ['distant', 'stars', 'each'] is 1\n",
      "count of this ['stars', 'each', 'harboring'] is 1\n",
      "count of this ['each', 'harboring', 'its'] is 1\n",
      "count of this ['harboring', 'its', 'own'] is 1\n",
      "count of this ['its', 'own', 'unique'] is 1\n",
      "count of this ['own', 'unique', 'collection'] is 1\n",
      "count of this ['unique', 'collection', 'of'] is 1\n",
      "count of this ['collection', 'of', 'celestial'] is 1\n",
      "count of this ['of', 'celestial', 'bodies'] is 1\n",
      "count of this ['celestial', 'bodies', 'from'] is 1\n",
      "count of this ['bodies', 'from', 'massive'] is 1\n",
      "count of this ['from', 'massive', 'black'] is 1\n",
      "count of this ['massive', 'black', 'holes'] is 1\n",
      "count of this ['black', 'holes', 'to'] is 1\n",
      "count of this ['holes', 'to', 'shimmering'] is 1\n",
      "count of this ['to', 'shimmering', 'nebulae'] is 1\n",
      "count of this ['shimmering', 'nebulae', 'all'] is 1\n",
      "count of this ['nebulae', 'all', 'governed'] is 1\n",
      "count of this ['all', 'governed', 'by'] is 1\n",
      "count of this ['governed', 'by', 'the'] is 1\n",
      "count of this ['by', 'the', 'laws'] is 1\n",
      "count of this ['the', 'laws', 'of'] is 1\n",
      "count of this ['laws', 'of', 'physics'] is 1\n",
      "count of this ['of', 'physics', 'and'] is 1\n",
      "count of this ['physics', 'and', 'the'] is 1\n",
      "count of this ['and', 'the', 'mysterious'] is 1\n",
      "count of this ['the', 'mysterious', 'forces'] is 1\n",
      "count of this ['mysterious', 'forces', 'that'] is 1\n",
      "count of this ['forces', 'that', 'shape'] is 1\n",
      "count of this ['that', 'shape', 'the'] is 1\n",
      "count of this ['shape', 'the', 'cosmos'] is 1\n"
     ]
    }
   ],
   "source": [
    "for i in ngram:\n",
    "    print(f'count of this {i} is {model.counts(i)[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count of this ['in', 'the'] is 0\n",
      "count of this ['the', 'vast'] is 0\n",
      "count of this ['vast', 'expanse'] is 0\n",
      "count of this ['expanse', 'of'] is 0\n",
      "count of this ['of', 'the'] is 0\n",
      "count of this ['the', 'universe'] is 0\n",
      "count of this ['universe', 'countless'] is 0\n",
      "count of this ['countless', 'galaxies'] is 0\n",
      "count of this ['galaxies', 'twinkle'] is 0\n",
      "count of this ['twinkle', 'like'] is 0\n",
      "count of this ['like', 'distant'] is 0\n",
      "count of this ['distant', 'stars'] is 0\n",
      "count of this ['stars', 'each'] is 0\n",
      "count of this ['each', 'harboring'] is 0\n",
      "count of this ['harboring', 'its'] is 0\n",
      "count of this ['its', 'own'] is 0\n",
      "count of this ['own', 'unique'] is 0\n",
      "count of this ['unique', 'collection'] is 0\n",
      "count of this ['collection', 'of'] is 0\n",
      "count of this ['of', 'celestial'] is 0\n",
      "count of this ['celestial', 'bodies'] is 0\n",
      "count of this ['bodies', 'from'] is 0\n",
      "count of this ['from', 'massive'] is 0\n",
      "count of this ['massive', 'black'] is 0\n",
      "count of this ['black', 'holes'] is 0\n",
      "count of this ['holes', 'to'] is 0\n",
      "count of this ['to', 'shimmering'] is 0\n",
      "count of this ['shimmering', 'nebulae'] is 0\n",
      "count of this ['nebulae', 'all'] is 0\n",
      "count of this ['all', 'governed'] is 0\n",
      "count of this ['governed', 'by'] is 0\n",
      "count of this ['by', 'the'] is 0\n",
      "count of this ['the', 'laws'] is 0\n",
      "count of this ['laws', 'of'] is 0\n",
      "count of this ['of', 'physics'] is 0\n",
      "count of this ['physics', 'and'] is 0\n",
      "count of this ['and', 'the'] is 0\n",
      "count of this ['the', 'mysterious'] is 0\n",
      "count of this ['mysterious', 'forces'] is 0\n",
      "count of this ['forces', 'that'] is 0\n",
      "count of this ['that', 'shape'] is 0\n",
      "count of this ['shape', 'the'] is 0\n"
     ]
    }
   ],
   "source": [
    "for i in context:\n",
    "    print(f'count of this {i} is {model.counts(i)[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.probability(['mysterious', 'forces', 'that'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "p = 1\n",
    "for i in ngram:\n",
    "    p *= model.probability(i)\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4641588.8336127745"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.perplexity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of 'the brown fox': 0.0\n",
      "Probability of 'jumps over the': 1.0\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "training_corpus = \"The quick brown fox jumps over the lazy dog. The dog barks loudly in the quiet night. Cats sleep peacefully on the soft couch. Birds sing joyfully in the early morning hours. The sun rises in the east, casting a warm glow over the countryside. The moon shines brightly in the clear night sky, illuminating the landscape below. People go to work in the bustling city, while children play in the colorful park nearby. Cars drive on the busy streets, creating a constant hum of activity. The city never sleeps, with restaurants and shops open throughout the night, offering a wide variety of entertainment and dining options.\"\n",
    "n = 3  # Use trigrams\n",
    "model1 = Ngram(training_corpus, n)\n",
    "\n",
    "# Calculate probabilities for different n-grams\n",
    "ngram1 = [\"the\", \"brown\", \"fox\"]\n",
    "ngram2 = [\"jumps\", \"over\", \"the\"]\n",
    "\n",
    "probability1 = model1.probability(ngram1)\n",
    "probability2 = model1.probability(ngram2)\n",
    "\n",
    "print(f\"Probability of '{' '.join(ngram1)}': {probability1}\")\n",
    "print(f\"Probability of '{' '.join(ngram2)}': {probability2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['the', 'quick', 'brown'], ['quick', 'brown', 'fox'], ['brown', 'fox', 'jumps'], ['fox', 'jumps', 'over'], ['jumps', 'over', 'the'], ['over', 'the', 'lazy'], ['the', 'lazy', 'dog'], ['lazy', 'dog', 'the'], ['dog', 'the', 'dog'], ['the', 'dog', 'barks'], ['dog', 'barks', 'loudly'], ['barks', 'loudly', 'in'], ['loudly', 'in', 'the'], ['in', 'the', 'quiet'], ['the', 'quiet', 'night'], ['quiet', 'night', 'cats'], ['night', 'cats', 'sleep'], ['cats', 'sleep', 'peacefully'], ['sleep', 'peacefully', 'on'], ['peacefully', 'on', 'the'], ['on', 'the', 'soft'], ['the', 'soft', 'couch'], ['soft', 'couch', 'birds'], ['couch', 'birds', 'sing'], ['birds', 'sing', 'joyfully'], ['sing', 'joyfully', 'in'], ['joyfully', 'in', 'the'], ['in', 'the', 'early'], ['the', 'early', 'morning'], ['early', 'morning', 'hours'], ['morning', 'hours', 'the'], ['hours', 'the', 'sun'], ['the', 'sun', 'rises'], ['sun', 'rises', 'in'], ['rises', 'in', 'the'], ['in', 'the', 'east'], ['the', 'east', 'casting'], ['east', 'casting', 'a'], ['casting', 'a', 'warm'], ['a', 'warm', 'glow'], ['warm', 'glow', 'over'], ['glow', 'over', 'the'], ['over', 'the', 'countryside'], ['the', 'countryside', 'the'], ['countryside', 'the', 'moon'], ['the', 'moon', 'shines'], ['moon', 'shines', 'brightly'], ['shines', 'brightly', 'in'], ['brightly', 'in', 'the'], ['in', 'the', 'clear'], ['the', 'clear', 'night'], ['clear', 'night', 'sky'], ['night', 'sky', 'illuminating'], ['sky', 'illuminating', 'the'], ['illuminating', 'the', 'landscape'], ['the', 'landscape', 'below'], ['landscape', 'below', 'people'], ['below', 'people', 'go'], ['people', 'go', 'to'], ['go', 'to', 'work'], ['to', 'work', 'in'], ['work', 'in', 'the'], ['in', 'the', 'bustling'], ['the', 'bustling', 'city'], ['bustling', 'city', 'while'], ['city', 'while', 'children'], ['while', 'children', 'play'], ['children', 'play', 'in'], ['play', 'in', 'the'], ['in', 'the', 'colorful'], ['the', 'colorful', 'park'], ['colorful', 'park', 'nearby'], ['park', 'nearby', 'cars'], ['nearby', 'cars', 'drive'], ['cars', 'drive', 'on'], ['drive', 'on', 'the'], ['on', 'the', 'busy'], ['the', 'busy', 'streets'], ['busy', 'streets', 'creating'], ['streets', 'creating', 'a'], ['creating', 'a', 'constant'], ['a', 'constant', 'hum'], ['constant', 'hum', 'of'], ['hum', 'of', 'activity'], ['of', 'activity', 'the'], ['activity', 'the', 'city'], ['the', 'city', 'never'], ['city', 'never', 'sleeps'], ['never', 'sleeps', 'with'], ['sleeps', 'with', 'restaurants'], ['with', 'restaurants', 'and'], ['restaurants', 'and', 'shops'], ['and', 'shops', 'open'], ['shops', 'open', 'throughout'], ['open', 'throughout', 'the'], ['throughout', 'the', 'night'], ['the', 'night', 'offering'], ['night', 'offering', 'a'], ['offering', 'a', 'wide'], ['a', 'wide', 'variety'], ['wide', 'variety', 'of'], ['variety', 'of', 'entertainment'], ['of', 'entertainment', 'and'], ['entertainment', 'and', 'dining'], ['and', 'dining', 'options']]\n"
     ]
    }
   ],
   "source": [
    "ngram11 = model1.ngram_context()[0]\n",
    "print(ngram11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['the', 'quick'], ['quick', 'brown'], ['brown', 'fox'], ['fox', 'jumps'], ['jumps', 'over'], ['over', 'the'], ['the', 'lazy'], ['lazy', 'dog'], ['dog', 'the'], ['the', 'dog'], ['dog', 'barks'], ['barks', 'loudly'], ['loudly', 'in'], ['in', 'the'], ['the', 'quiet'], ['quiet', 'night'], ['night', 'cats'], ['cats', 'sleep'], ['sleep', 'peacefully'], ['peacefully', 'on'], ['on', 'the'], ['the', 'soft'], ['soft', 'couch'], ['couch', 'birds'], ['birds', 'sing'], ['sing', 'joyfully'], ['joyfully', 'in'], ['in', 'the'], ['the', 'early'], ['early', 'morning'], ['morning', 'hours'], ['hours', 'the'], ['the', 'sun'], ['sun', 'rises'], ['rises', 'in'], ['in', 'the'], ['the', 'east'], ['east', 'casting'], ['casting', 'a'], ['a', 'warm'], ['warm', 'glow'], ['glow', 'over'], ['over', 'the'], ['the', 'countryside'], ['countryside', 'the'], ['the', 'moon'], ['moon', 'shines'], ['shines', 'brightly'], ['brightly', 'in'], ['in', 'the'], ['the', 'clear'], ['clear', 'night'], ['night', 'sky'], ['sky', 'illuminating'], ['illuminating', 'the'], ['the', 'landscape'], ['landscape', 'below'], ['below', 'people'], ['people', 'go'], ['go', 'to'], ['to', 'work'], ['work', 'in'], ['in', 'the'], ['the', 'bustling'], ['bustling', 'city'], ['city', 'while'], ['while', 'children'], ['children', 'play'], ['play', 'in'], ['in', 'the'], ['the', 'colorful'], ['colorful', 'park'], ['park', 'nearby'], ['nearby', 'cars'], ['cars', 'drive'], ['drive', 'on'], ['on', 'the'], ['the', 'busy'], ['busy', 'streets'], ['streets', 'creating'], ['creating', 'a'], ['a', 'constant'], ['constant', 'hum'], ['hum', 'of'], ['of', 'activity'], ['activity', 'the'], ['the', 'city'], ['city', 'never'], ['never', 'sleeps'], ['sleeps', 'with'], ['with', 'restaurants'], ['restaurants', 'and'], ['and', 'shops'], ['shops', 'open'], ['open', 'throughout'], ['throughout', 'the'], ['the', 'night'], ['night', 'offering'], ['offering', 'a'], ['a', 'wide'], ['wide', 'variety'], ['variety', 'of'], ['of', 'entertainment'], ['entertainment', 'and'], ['and', 'dining']]\n"
     ]
    }
   ],
   "source": [
    "print(model1.ngram_context()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.counts(ngram1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.counts(ngram1)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lapalcae smoothing, Add-k smoothing, Entropy ? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive-Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This is a positive sentence.', 'Negative sentiment here.', 'Another positive example.', 'More negative text.']\n",
      "['text', 'a', 'sentiment', 'example', 'positive', 'negative', 'here', 'another', 'is', 'sentence', 'more', 'this']\n",
      "Positive sentiment\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "# Sample text data (replace with your own dataset)\n",
    "texts = [\"This is a positive sentence.\", \"Negative sentiment here.\", \"Another positive example.\", \"More negative text.\"]\n",
    "print(texts)\n",
    "labels = [1, 0, 1, 0]  # 1 for positive, 0 for negative\n",
    "\n",
    "# Preprocess the text data\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    text = text.replace('.', '')  # Remove periods\n",
    "    text = text.replace(',', '')  # Remove commas\n",
    "    text = text.replace('!', '')  # Remove exclamation marks\n",
    "    text = text.replace('?', '')  # Remove question marks\n",
    "    text = text.replace('\"', '')  # Remove double quotes\n",
    "    text = text.replace(\"'\", '')  # Remove single quotes\n",
    "    text = text.replace('(', '')  # Remove opening parentheses\n",
    "    text = text.replace(')', '')  # Remove closing parentheses\n",
    "    text = text.split()  # Tokenize by whitespace\n",
    "    return text\n",
    "\n",
    "# Calculate the prior probabilities\n",
    "total_samples = len(texts)\n",
    "positive_samples = sum(labels)\n",
    "negative_samples = total_samples - positive_samples\n",
    "prior_positive = positive_samples / total_samples\n",
    "prior_negative = negative_samples / total_samples\n",
    "\n",
    "# Create a vocabulary of unique words\n",
    "vocabulary = set()\n",
    "for text in texts:\n",
    "    words = preprocess_text(text)\n",
    "    vocabulary.update(words)\n",
    "vocabulary = list(vocabulary)\n",
    "\n",
    "print(vocabulary)\n",
    "\n",
    "# Calculate word frequencies in positive and negative classes\n",
    "positive_word_counts = {word: 0 for word in vocabulary}\n",
    "negative_word_counts = {word: 0 for word in vocabulary}\n",
    "\n",
    "for i, text in enumerate(texts):\n",
    "    words = preprocess_text(text)\n",
    "    for word in words:\n",
    "        if labels[i] == 1:\n",
    "            positive_word_counts[word] += 1\n",
    "        else:\n",
    "            negative_word_counts[word] += 1\n",
    "\n",
    "# Calculate conditional probabilities (likelihoods)\n",
    "smooth_factor = 1  # Laplace smoothing to avoid zero probabilities\n",
    "positive_likelihoods = {}\n",
    "negative_likelihoods = {}\n",
    "\n",
    "for word in vocabulary:\n",
    "    positive_likelihoods[word] = (positive_word_counts[word] + smooth_factor) / (positive_samples + smooth_factor * len(vocabulary))\n",
    "    negative_likelihoods[word] = (negative_word_counts[word] + smooth_factor) / (negative_samples + smooth_factor * len(vocabulary))\n",
    "\n",
    "# Classify new text\n",
    "def classify_text(text):\n",
    "    words = preprocess_text(text)\n",
    "    log_prob_positive = math.log(prior_positive)\n",
    "    log_prob_negative = math.log(prior_negative)\n",
    "    \n",
    "    for word in words:\n",
    "        if word in vocabulary:\n",
    "            log_prob_positive += math.log(positive_likelihoods[word])\n",
    "            log_prob_negative += math.log(negative_likelihoods[word])\n",
    "    \n",
    "    if log_prob_positive > log_prob_negative:\n",
    "        return 1  # Positive class\n",
    "    else:\n",
    "        return 0  # Negative class\n",
    "\n",
    "# Test the classifier\n",
    "new_text = \"This is a test of the Naive Bayes classifier.\"\n",
    "predicted_label = classify_text(new_text)\n",
    "if predicted_label == 1:\n",
    "    print(\"Positive sentiment\")\n",
    "else:\n",
    "    print(\"Negative sentiment\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression (sigmoid activation function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive sentiment\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Sample text data (replace with your own dataset)\n",
    "texts = [\"This is a positive sentence.\", \"Negative sentiment here.\", \"Another positive example.\", \"More negative text.\"]\n",
    "labels = [1, 0, 1, 0]  # 1 for positive, 0 for negative\n",
    "\n",
    "# Preprocess the text data\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    text = text.replace('.', '')  # Remove periods\n",
    "    text = text.replace(',', '')  # Remove commas\n",
    "    text = text.replace('!', '')  # Remove exclamation marks\n",
    "    text = text.replace('?', '')  # Remove question marks\n",
    "    text = text.replace('\"', '')  # Remove double quotes\n",
    "    text = text.replace(\"'\", '')  # Remove single quotes\n",
    "    text = text.replace('(', '')  # Remove opening parentheses\n",
    "    text = text.replace(')', '')  # Remove closing parentheses\n",
    "    text = text.split()  # Tokenize by whitespace\n",
    "    return text\n",
    "\n",
    "# Create a vocabulary of unique words\n",
    "vocabulary = set()\n",
    "for text in texts:\n",
    "    words = preprocess_text(text)\n",
    "    vocabulary.update(words)\n",
    "vocabulary = list(vocabulary)\n",
    "\n",
    "# Create a feature matrix (X) and target vector (y)\n",
    "X = np.zeros((len(texts), len(vocabulary)))\n",
    "y = np.array(labels)\n",
    "\n",
    "# Convert text data into a binary bag-of-words representation\n",
    "for i, text in enumerate(texts):\n",
    "    words = preprocess_text(text)\n",
    "    for j, word in enumerate(vocabulary):\n",
    "        if word in words:\n",
    "            X[i][j] = 1\n",
    "\n",
    "# Initialize weights and bias\n",
    "num_features = len(vocabulary)\n",
    "weights = np.zeros(num_features)\n",
    "bias = 0\n",
    "\n",
    "# Sigmoid activation function\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "# Train the logistic regression model using gradient descent\n",
    "learning_rate = 0.01\n",
    "num_epochs = 1000\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Compute predictions\n",
    "    predictions = sigmoid(np.dot(X, weights) + bias)\n",
    "    \n",
    "    # Compute gradients\n",
    "    dw = (1 / len(texts)) * np.dot(X.T, (predictions - y))\n",
    "    db = (1 / len(texts)) * np.sum(predictions - y)\n",
    "    \n",
    "    # Update weights and bias\n",
    "    weights -= learning_rate * dw\n",
    "    bias -= learning_rate * db\n",
    "\n",
    "# Classify new text\n",
    "def classify_text(text):\n",
    "    words = preprocess_text(text)\n",
    "    input_features = np.zeros(num_features)\n",
    "    \n",
    "    for j, word in enumerate(vocabulary):\n",
    "        if word in words:\n",
    "            input_features[j] = 1\n",
    "    \n",
    "    prediction = sigmoid(np.dot(input_features, weights) + bias)\n",
    "    return prediction\n",
    "\n",
    "# Test the classifier\n",
    "new_text = \"This is a test of the Logistic Regression classifier.\"\n",
    "predicted_prob = classify_text(new_text)\n",
    "if predicted_prob > 0.5:\n",
    "    print(\"Positive sentiment\")\n",
    "else:\n",
    "    print(\"Negative sentiment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression (softmax activation function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive sentiment\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Sample text data (replace with your own dataset)\n",
    "texts = [\"This is a positive sentence.\", \"Negative sentiment here.\", \"Another positive example.\", \"More negative text.\"]\n",
    "labels = [1, 0, 1, 0]  # 1 for positive, 0 for negative\n",
    "\n",
    "# Preprocess the text data\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    text = text.replace('.', '')  # Remove periods\n",
    "    text = text.replace(',', '')  # Remove commas\n",
    "    text = text.replace('!', '')  # Remove exclamation marks\n",
    "    text = text.replace('?', '')  # Remove question marks\n",
    "    text = text.replace('\"', '')  # Remove double quotes\n",
    "    text = text.replace(\"'\", '')  # Remove single quotes\n",
    "    text = text.replace('(', '')  # Remove opening parentheses\n",
    "    text = text.replace(')', '')  # Remove closing parentheses\n",
    "    text = text.split()  # Tokenize by whitespace\n",
    "    return text\n",
    "\n",
    "# Create a vocabulary of unique words\n",
    "vocabulary = set()\n",
    "for text in texts:\n",
    "    words = preprocess_text(text)\n",
    "    vocabulary.update(words)\n",
    "vocabulary = list(vocabulary)\n",
    "\n",
    "# Create a feature matrix (X) and target vector (y)\n",
    "X = np.zeros((len(texts), len(vocabulary)))\n",
    "y = np.array(labels)\n",
    "\n",
    "# Convert text data into a binary bag-of-words representation\n",
    "for i, text in enumerate(texts):\n",
    "    words = preprocess_text(text)\n",
    "    for j, word in enumerate(vocabulary):\n",
    "        if word in words:\n",
    "            X[i][j] = 1\n",
    "\n",
    "# Initialize weights and bias\n",
    "num_features = len(vocabulary)\n",
    "weights = np.zeros(num_features)\n",
    "bias = 0\n",
    "\n",
    "# Softmax activation function\n",
    "def softmax(z):\n",
    "    exp_z = np.exp(z - np.max(z))  # Subtract max(z) to prevent overflow\n",
    "    return exp_z / exp_z.sum(axis=0, keepdims=True)\n",
    "\n",
    "# Define the cross-entropy loss\n",
    "def cross_entropy_loss(y_true, y_pred):\n",
    "    epsilon = 1e-15  # Small constant to avoid division by zero\n",
    "    y_pred = np.clip(y_pred, epsilon, 1 - epsilon)  # Clip predicted values to prevent log(0)\n",
    "    return -np.sum(y_true * np.log(y_pred))\n",
    "\n",
    "# Train the logistic regression model using gradient descent\n",
    "learning_rate = 0.01\n",
    "num_epochs = 1000\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Compute predictions\n",
    "    z = np.dot(X, weights) + bias\n",
    "    predictions = softmax(z)\n",
    "    \n",
    "    # Compute gradients\n",
    "    dw = (1 / len(texts)) * np.dot(X.T, (predictions - y))\n",
    "    db = (1 / len(texts)) * np.sum(predictions - y)\n",
    "    \n",
    "    # Update weights and bias\n",
    "    weights -= learning_rate * dw\n",
    "    bias -= learning_rate * db\n",
    "\n",
    "# Classify new text\n",
    "def classify_text(text):\n",
    "    words = preprocess_text(text)\n",
    "    input_features = np.zeros(num_features)\n",
    "    \n",
    "    for j, word in enumerate(vocabulary):\n",
    "        if word in words:\n",
    "            input_features[j] = 1\n",
    "    \n",
    "    prediction = softmax(np.dot(input_features, weights) + bias)\n",
    "    return prediction\n",
    "\n",
    "# Test the classifier\n",
    "new_text = \"This is a test of the Logistic Regression classifier.\"\n",
    "predicted_prob = classify_text(new_text)\n",
    "if predicted_prob > 0.5:\n",
    "    print(\"Positive sentiment\")\n",
    "else:\n",
    "    print(\"Negative sentiment\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression (using scikit-learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://bookdown.org/f_lennert/book-toolbox_css/text-mining.html#tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Expected 5 fields in line 18, saw 7\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m/Users/manideep/Downloads/NLP/git_repo/NLP/NLP_workbook.ipynb Cell 33\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/manideep/Downloads/NLP/git_repo/NLP/NLP_workbook.ipynb#Y106sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39m\"\u001b[39;49m\u001b[39mimdb_reviews.csv\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/io/parsers/readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    944\u001b[0m     dtype_backend\u001b[39m=\u001b[39mdtype_backend,\n\u001b[1;32m    945\u001b[0m )\n\u001b[1;32m    946\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 948\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/io/parsers/readers.py:617\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    614\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n\u001b[1;32m    616\u001b[0m \u001b[39mwith\u001b[39;00m parser:\n\u001b[0;32m--> 617\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\u001b[39m.\u001b[39;49mread(nrows)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1748\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1741\u001b[0m nrows \u001b[39m=\u001b[39m validate_integer(\u001b[39m\"\u001b[39m\u001b[39mnrows\u001b[39m\u001b[39m\"\u001b[39m, nrows)\n\u001b[1;32m   1742\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1743\u001b[0m     \u001b[39m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m     (\n\u001b[1;32m   1745\u001b[0m         index,\n\u001b[1;32m   1746\u001b[0m         columns,\n\u001b[1;32m   1747\u001b[0m         col_dict,\n\u001b[0;32m-> 1748\u001b[0m     ) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mread(  \u001b[39m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[1;32m   1749\u001b[0m         nrows\n\u001b[1;32m   1750\u001b[0m     )\n\u001b[1;32m   1751\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[1;32m   1752\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/io/parsers/c_parser_wrapper.py:234\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    233\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlow_memory:\n\u001b[0;32m--> 234\u001b[0m         chunks \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_reader\u001b[39m.\u001b[39;49mread_low_memory(nrows)\n\u001b[1;32m    235\u001b[0m         \u001b[39m# destructive to chunks\u001b[39;00m\n\u001b[1;32m    236\u001b[0m         data \u001b[39m=\u001b[39m _concatenate_chunks(chunks)\n",
      "File \u001b[0;32mparsers.pyx:843\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsers.pyx:904\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsers.pyx:879\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsers.pyx:890\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsers.pyx:2058\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 5 fields in line 18, saw 7\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"imdb_reviews.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF Vectorisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
